{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912eada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain_tavily in /home/suavendas/.local/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: langgraph in /home/suavendas/.local/lib/python3.12/site-packages (0.4.0)\n",
      "Requirement already satisfied: pydantic-ai in /home/suavendas/.local/lib/python3.12/site-packages (0.1.8)\n",
      "Requirement already satisfied: pydantic in /home/suavendas/.local/lib/python3.12/site-packages (2.11.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain_tavily) (3.11.16)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain_tavily) (0.3.24)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain_tavily) (0.3.56)\n",
      "Requirement already satisfied: mypy<2.0.0,>=1.15.0 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain_tavily) (1.15.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain_tavily) (2.32.3)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /home/suavendas/.local/lib/python3.12/site-packages (from langgraph) (2.0.25)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /home/suavendas/.local/lib/python3.12/site-packages (from langgraph) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in /home/suavendas/.local/lib/python3.12/site-packages (from langgraph) (0.1.64)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /home/suavendas/.local/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: pydantic-ai-slim==0.1.8 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.1.8)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.2.2)\n",
      "Requirement already satisfied: griffe>=1.3.2 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.7.3)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.31.1)\n",
      "Requirement already satisfied: pydantic-graph==0.1.8 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.1.8)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: anthropic>=0.49.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.50.0)\n",
      "Requirement already satisfied: boto3>=1.35.74 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.37.29)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (3.6.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (3.0.50)\n",
      "Requirement already satisfied: rich>=13 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (14.0.0)\n",
      "Requirement already satisfied: cohere>=5.13.11 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (5.15.0)\n",
      "Requirement already satisfied: pydantic-evals==0.1.8 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.1.8)\n",
      "Requirement already satisfied: groq>=0.15.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.23.1)\n",
      "Requirement already satisfied: mcp>=1.6.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.7.1)\n",
      "Requirement already satisfied: mistralai>=1.2.5 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.7.0)\n",
      "Requirement already satisfied: openai>=1.75.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.76.2)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (2.39.0)\n",
      "Requirement already satisfied: anyio>=0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-evals==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (4.9.0)\n",
      "Requirement already satisfied: logfire-api>=1.2.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-evals==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (3.14.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-evals==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (6.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic) (4.13.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/suavendas/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/suavendas/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/suavendas/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/suavendas/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/suavendas/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/suavendas/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.18.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (0.3.38)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (1.4.54)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_tavily) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_tavily) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/suavendas/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_tavily) (24.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /home/suavendas/.local/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/suavendas/.local/lib/python3.12/site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: mypy_extensions>=1.0.0 in /home/suavendas/.local/lib/python3.12/site-packages (from mypy<2.0.0,>=1.15.0->langchain_tavily) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/suavendas/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->langchain_tavily) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.32.3->langchain_tavily) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.32.3->langchain_tavily) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/suavendas/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->langchain_tavily) (2025.1.31)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/suavendas/.local/lib/python3.12/site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /home/suavendas/.local/lib/python3.12/site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.3.1)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.29 in /home/suavendas/.local/lib/python3.12/site-packages (from boto3>=1.35.74->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.37.29)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/suavendas/.local/lib/python3.12/site-packages (from boto3>=1.35.74->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/suavendas/.local/lib/python3.12/site-packages (from boto3>=1.35.74->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.11.4)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /home/suavendas/.local/lib/python3.12/site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.10.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /home/suavendas/.local/lib/python3.12/site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /home/suavendas/.local/lib/python3.12/site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.21.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /home/suavendas/.local/lib/python3.12/site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (2.32.0.20250328)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/suavendas/.local/lib/python3.12/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/suavendas/.local/lib/python3.12/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (4.9)\n",
      "Requirement already satisfied: colorama>=0.4 in /usr/lib/python3/dist-packages (from griffe>=1.3.2->pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in /home/suavendas/.local/lib/python3.12/site-packages (from httpx>=0.27->pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/suavendas/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_tavily) (2.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/lib/python3/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/suavendas/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (0.23.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/suavendas/.local/lib/python3.12/site-packages (from mcp>=1.6.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/suavendas/.local/lib/python3.12/site-packages (from mcp>=1.6.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /home/suavendas/.local/lib/python3.12/site-packages (from mcp>=1.6.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (2.3.3)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/suavendas/.local/lib/python3.12/site-packages (from mcp>=1.6.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in /home/suavendas/.local/lib/python3.12/site-packages (from mcp>=1.6.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.30.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/suavendas/.local/lib/python3.12/site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>4 in /home/suavendas/.local/lib/python3.12/site-packages (from openai>=1.75.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (4.67.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/suavendas/.local/lib/python3.12/site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/suavendas/.local/lib/python3.12/site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (6.11.0)\n",
      "Requirement already satisfied: wcwidth in /home/suavendas/.local/lib/python3.12/site-packages (from prompt-toolkit>=3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/lib/python3/dist-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/suavendas/.local/lib/python3.12/site-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/suavendas/.local/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain_tavily) (3.1.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/suavendas/.local/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.17.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/suavendas/.local/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.1.8->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/lib/python3/dist-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.1.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/suavendas/.local/lib/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp>=1.6.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/suavendas/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.4.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/suavendas/.local/lib/python3.12/site-packages (from tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (0.30.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/suavendas/.local/lib/python3.12/site-packages (from uvicorn>=0.23.1->mcp>=1.6.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (8.1.8)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/suavendas/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.1.8->pydantic-ai) (2025.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages langchain_tavily langgraph pydantic-ai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322e1648",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'chatbot_with_safe_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 226\u001b[39m\n\u001b[32m    223\u001b[39m graph_builder.set_finish_point(\u001b[33m\"\u001b[39m\u001b[33mend_conversation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Compilação com checkpoint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m graph_obj = \u001b[43mgraph_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMemorySaver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    230\u001b[39m     display(Image(graph_obj.get_graph().draw_mermaid_png()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/langgraph/graph/state.py:610\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    607\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    609\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    619\u001b[39m output_channels = (\n\u001b[32m    620\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    627\u001b[39m     ]\n\u001b[32m    628\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/langgraph/graph/graph.py:257\u001b[39m, in \u001b[36mGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m source != START:\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    261\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found edge starting at unknown node 'chatbot_with_safe_tools'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import interrupt\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_tavily import TavilySearch\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --------------------------\n",
    "# Estado e tipo do fluxo\n",
    "# --------------------------\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "class UserIntent(BaseModel):\n",
    "    intent: Literal[\"exit\", \"continue\"]\n",
    "\n",
    "class ConfirmationIntent(str, Enum):\n",
    "    confirm = \"confirm\"\n",
    "    deny = \"deny\"\n",
    "    unclear = \"unclear\"\n",
    "\n",
    "class ConfirmationOutput(BaseModel):\n",
    "    intent: ConfirmationIntent = Field(\n",
    "        ...,\n",
    "        description=\"User confirmation intent: 'confirm' if user agreed, 'deny' if refused, or 'unclear' if ambiguous.\"\n",
    "    )\n",
    "\n",
    "# --------------------------\n",
    "# Ferramentas\n",
    "# --------------------------\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "search_tool = TavilySearch(max_results=2)\n",
    "safe_tools = [search_tool]\n",
    "sensitive_tools = [human_assistance]\n",
    "\n",
    "# --------------------------\n",
    "# Models\n",
    "# --------------------------\n",
    "\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai:o3-mini\")\n",
    "\n",
    "safe_llm = init_chat_model(LLM_MODEL).bind_tools(safe_tools)\n",
    "sensitive_llm = init_chat_model(LLM_MODEL).bind_tools(sensitive_tools)\n",
    "\n",
    "# --------------------------\n",
    "# Nodes\n",
    "# --------------------------\n",
    "\n",
    "def chatbot_with_safe_tools(state: State):\n",
    "    message = safe_llm.invoke(state[\"messages\"])\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "def confirm_topic_node(state: State):\n",
    "    confirm_msg = HumanMessage(content=\"Do you want me to consult a human on this topic? (yes/no)\")\n",
    "    return {\"messages\": [confirm_msg]}\n",
    "\n",
    "def sensitive_tool_handler(state: State):\n",
    "    message = sensitive_llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "def end_conversation_node(state: State):\n",
    "    message = safe_llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# --------------------------\n",
    "# Decision agents\n",
    "# --------------------------\n",
    "\n",
    "intent_classifier = Agent(\n",
    "    model=LLM_MODEL,\n",
    "    output_type=UserIntent,\n",
    "    system_prompt=\"\"\"\n",
    "Classify the user's intent.\n",
    "\n",
    "Respond only with JSON:\n",
    "\n",
    "{ \"intent\": \"exit\" }      # if user wants to quit\n",
    "{ \"intent\": \"continue\" }  # if user wants to keep chatting\n",
    "\"\"\",\n",
    "    retries=2,\n",
    ")\n",
    "\n",
    "confirmation_classifier = Agent(\n",
    "    model=LLM_MODEL,\n",
    "    output_type=ConfirmationOutput,\n",
    "    system_prompt=\"\"\"\n",
    "You are a confirmation intent classifier.\n",
    "\n",
    "Given a user message, classify it into:\n",
    "- \"confirm\" if user agrees\n",
    "- \"deny\" if user declines\n",
    "- \"unclear\" if ambiguous, sarcastic, or unrelated\n",
    "\n",
    "Respond only in this JSON format:\n",
    "{ \"intent\": \"confirm\" }\n",
    "\"\"\",\n",
    "    retries=2,\n",
    ")\n",
    "\n",
    "def check_user_intent(state: State) -> str:\n",
    "    last_user_msg = next(m for m in reversed(state[\"messages\"]) if isinstance(m, HumanMessage))\n",
    "    result = intent_classifier.run_sync(last_user_msg.content)\n",
    "    intent = result.output.intent\n",
    "    print(f\"[Intent → {intent}]\")\n",
    "    return intent\n",
    "\n",
    "def detect_sensitive_case(state: State) -> bool:\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    return hasattr(last_msg, \"tool_calls\") and \\\n",
    "        last_msg.tool_calls and \\\n",
    "        last_msg.tool_calls[0][\"name\"] == \"human_assistance\"\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "def handle_user_confirmation(state: State) -> str:\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if not isinstance(last_msg, HumanMessage):\n",
    "        return \"unclear\"\n",
    "\n",
    "    # Initialize retry counter if not present\n",
    "    retries = state.get(\"confirmation_retries\", 0)\n",
    "\n",
    "    result = confirmation_classifier.invoke(last_msg.content)\n",
    "    intent = result.intent.value  # \"confirm\", \"deny\", or \"unclear\"\n",
    "\n",
    "    if intent == \"unclear\":\n",
    "        retries += 1\n",
    "        state[\"confirmation_retries\"] = retries\n",
    "        if retries >= MAX_RETRIES:\n",
    "            print(\"[Confirmation retries exhausted, defaulting to 'deny']\")\n",
    "            return \"deny\"\n",
    "        return \"unclear\"\n",
    "    else:\n",
    "        # Reset retries on clear answer\n",
    "        if \"confirmation_retries\" in state:\n",
    "            del state[\"confirmation_retries\"]\n",
    "        return intent\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Graph\n",
    "# --------------------------\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Node definitions\n",
    "graph_builder.add_node(\"which_intent_decision\", lambda state: {})\n",
    "graph_builder.add_node(\"chatbot_with_safe_tools_node\", chatbot_with_safe_tools)\n",
    "graph_builder.add_node(\"safe_tools\", ToolNode(tools=safe_tools))\n",
    "graph_builder.add_node(\"sensitive_tools\", ToolNode(tools=sensitive_tools))\n",
    "graph_builder.add_node(\"is_sensitive_decision\", detect_sensitive_case)\n",
    "graph_builder.add_node(\"awaiting_user_confirmation_decision\", handle_user_confirmation)\n",
    "graph_builder.add_node(\"human_assistance_node\", lambda state: {\"messages\": state.messages})\n",
    "graph_builder.add_node(\"end_conversation_node\", end_conversation_node)\n",
    "\n",
    "# Transitions\n",
    "graph_builder.add_edge(START, \"which_intent_decision\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"which_intent_decision\",\n",
    "    check_user_intent, \n",
    "    {\n",
    "        \"continue\": \"chatbot_with_safe_tools_node\",\n",
    "        \"exit\": \"end_conversation\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot_with_safe_tools\", \n",
    "    tools_condition, \n",
    "    {\n",
    "        True: \"safe_tools\",\n",
    "        False: \"is_sensitive_node\"\n",
    "    }\n",
    ")\n",
    "graph_builder.add_edge(\"safe_tools\", \"chatbot_with_safe_tools_node\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"detect_sensitive_case\", \n",
    "    detect_sensitive_case, \n",
    "    {\n",
    "        True: \"awaiting_user_confirmation\",\n",
    "        False: \"chatbot_with_safe_tools_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"awaiting_user_confirmation\", \n",
    "    handle_user_confirmation,\n",
    "    {\n",
    "        \"confirm\": \"human_assistance\",\n",
    "        \"deny\": \"chatbot_with_safe_tools_node\",\n",
    "        \"unclear\": \"awaiting_user_confirmation\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"human_assistance\", \"sensitive_tools\")\n",
    "graph_builder.add_edge(\"sensitive_tools\", \"chatbot_with_safe_tools_node\")\n",
    "\n",
    "graph_builder.set_finish_point(\"end_conversation\")\n",
    "\n",
    "# Compilação com checkpoint\n",
    "graph_obj = graph_builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "\n",
    "try:\n",
    "    display(Image(graph_obj.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a4000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
